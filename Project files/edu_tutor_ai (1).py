# -*- coding: utf-8 -*-
"""Edu tutor AI

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NSC3aKEKX2mTtp7dn9MUZvLY2ihX0c02
"""

# Cell 1: Install Required Libraries (CORRECTED)
!pip install streamlit transformers torch google-auth-oauthlib google-api-python-client pinecone # Changed pinecone-client to pinecone
!pip install pyngrok
!pip install accelerate bitsandbytes # Recommended for optimizing model loading on GPU

# Commented out IPython magic to ensure Python compatibility.
# # Cell 2: Create the EduTutor AI Streamlit Application File (edututor_app.py)
# %%writefile edututor_app.py
# import streamlit as st
# import os
# import time
# import json
# from datetime import datetime
# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
# import torch
# import logging
# import re # Import regular expression module
# 
# # For Google Classroom API (requires client_secret.json)
# from google_auth_oauthlib.flow import Flow
# from google.auth.transport.requests import Request
# from google.oauth2.credentials import Credentials
# from googleapiclient.discovery import build
# import pickle
# os.environ["HUGGING_FACE_TOKEN"] = "your_HUGGINGFACE_token"
# 
# # For Pinecone
# from pinecone import Pinecone, ServerlessSpec # Import ServerlessSpec for index creation
# 
# # For IBM Watsonx (if used via LangChain)
# # from langchain_ibm import WatsonxLLM
# 
# # --- 0. Configuration and Environment Variables ---
# # Configure logging
# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
# 
# # Directly use os.environ.get for API keys to avoid StreamlitSecretNotFoundError in Colab
# # Your provided keys are inserted directly here.
# HF_TOKEN = os.environ.get("HUGGING_FACE_TOKEN")
# NGROK_AUTH_TOKEN = os.environ.get("NGROK_AUTH_TOKEN", "2z2tuNwzSHqpRx3xbCbWHjG1dRc_4ix8ZspVPU4cgQ7wrfDew")
# PINECONE_API_KEY = os.environ.get("PINECONE_API_KEY", "pcsk_3maR9W_LNaQh3q91Di5p3ZZrPM2JjKyxfsxwST5VQNV2hQ5hVsC27T3U6uKMNS5oeRJp13")
# PINECONE_INDEX_NAME = os.environ.get("PINECONE_INDEX_NAME", "edututorai-index") # Updated Pinecone index name
# # Add Pinecone Environment/Region based on your screenshot (us-east-1)
# PINECONE_ENVIRONMENT = os.environ.get("PINECONE_ENVIRONMENT", "us-east-1")
# WATSONX_API_KEY = os.environ.get("WATSONX_API_KEY", "TR27W9VvHDpjivMSdcY4j7k51gcQ8Ak1UU-_0HFfN4Xt")
# WATSONX_PROJECT_ID = os.environ.get("WATSONX_PROJECT_ID", "ea331d22-28c3-477f-94ce-e20d425b1acd")
# 
# 
# # --- 1. Model Loading (IBM Granite from Hugging Face) ---
# # Cache the model loading to prevent reloading on every Streamlit rerun
# @st.cache_resource
# def load_granite_model():
#     """Loads the IBM Granite model and tokenizer from Hugging Face."""
#     model_name = "ibm-granite/granite-3.3-2b-instruct"
#     logging.info(f"Loading model: {model_name}...")
#     try:
#         tokenizer = AutoTokenizer.from_pretrained(model_name, token=HF_TOKEN)
#         model = AutoModelForCausalLM.from_pretrained(
#             model_name,
#             torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,
#             trust_remote_code=True,
#             token=HF_TOKEN,
#             # load_in_8bit=True # Uncomment if you face memory issues and have bitsandbytes installed
#         )
#         if torch.cuda.is_available():
#             model.to("cuda")
#             logging.info("Model moved to GPU.")
#         else:
#             logging.warning("CUDA not available. Model running on CPU (might be slow).")
# 
#         text_generator = pipeline(
#             "text-generation",
#             model=model,
#             tokenizer=tokenizer,
#             max_new_tokens=250, # Increased for more comprehensive answers
#             do_sample=True,
#             temperature=0.7,
#             top_p=0.9,
#             repetition_penalty=1.2,
#             eos_token_id=tokenizer.eos_token_id,
#         )
#         logging.info("Model and pipeline loaded successfully!")
#         return text_generator
#     except Exception as e:
#         logging.error(f"Error loading model: {e}", exc_info=True)
#         st.error(f"Failed to load AI model: {e}. Please check your Hugging Face token and Colab runtime (GPU recommended).")
#         return None
# 
# text_generator = load_granite_model()
# 
# # --- Optional: IBM Watsonx Model Setup (if you want to use it for specific tasks) ---
# # @st.cache_resource
# # def load_watsonx_model():
# #     """Loads an IBM Watsonx model using LangChain."""
# #     if not WATSONX_API_KEY or not WATSONX_PROJECT_ID:
# #         st.warning("Watsonx API Key or Project ID not set. Watsonx features will not be available.")
# #         return None
# #     try:
# #         watsonx_model = WatsonxLLM(
# #             model_id="granite-13b-instruct-v2", # Or WATSONX_MODEL_ID from .env
# #             url="https://us-south.ml.cloud.ibm.com", # Or WATSONX_ENDPOINT
# #             project_id=WATSONX_PROJECT_ID,
# #             api_key=WATSONX_API_KEY,
# #             params={"decoding_method": "greedy", "min_new_tokens": 1, "max_new_tokens": 250}
# #         )
# #         logging.info("IBM Watsonx model loaded successfully!")
# #         return watsonx_model
# #     except Exception as e:
# #         logging.error(f"Error loading Watsonx model: {e}", exc_info=True)
# #         st.error(f"Failed to load IBM Watsonx model: {e}. Check your API key and project ID.")
# #         return None
# 
# # watsonx_llm = load_watsonx_model() # Uncomment to load Watsonx model
# 
# 
# # --- 2. AI Utility Functions ---
# 
# def generate_quiz(topic: str, num_questions: int = 3):
#     """Generates a quiz on a given topic using the LLM."""
#     if text_generator is None:
#         return {"error": "AI model not loaded."}
# 
#     prompt = (
#         f"Generate a {num_questions}-question multiple-choice quiz about '{topic}'. "
#         "Your response MUST be a JSON array of objects, and contain ONLY the JSON. "
#         "Do NOT include any introductory or concluding text, explanations, or markdown code block fences (```json). "
#         "Each object in the array MUST have 'question' (string), 'options' (array of 4 strings), and 'correct_answer' (string, A, B, C, or D). "
#         "Example: [{\"question\": \"What is X?\", \"options\": [\"A. Opt1\", \"B. Opt2\", \"C. Opt3\", \"D. Opt4\"], \"correct_answer\": \"A\"}]"
#     )
#     logging.info(f"Generating quiz for topic: '{topic}' with prompt: {prompt}")
# 
#     try:
#         result = text_generator(prompt)
#         raw_generated_text = result[0]['generated_text']
# 
#         # Attempt to remove the prompt from the generated text
#         # This is a robust way to handle the model echoing the prompt
#         # We also remove any common conversational prefixes like '[Response]' or 'Response:'
#         clean_generated_text = raw_generated_text.replace(prompt, "", 1).strip() # Replace only first occurrence
#         clean_generated_text = re.sub(r'^(?:\[Response\]|Response:)\s*', '', clean_generated_text, flags=re.IGNORECASE).strip()
# 
# 
#         json_str = ""
#         # Use a more specific regex to find a JSON array of objects
#         # It looks for '[' followed by optional whitespace, then '{', then any characters non-greedily,
#         # then '}', then any characters non-greedily, then ']'
#         match = re.search(r'\[\s*\{.*?\}\s*(?:,\s*\{.*?\})*\s*\]', clean_generated_text, re.DOTALL | re.MULTILINE)
#         if match:
#             json_str = match.group(0).strip() # Strip whitespace from the extracted JSON string
# 
#         if json_str:
#             quiz_data = json.loads(json_str)
#             logging.info(f"Generated quiz: {quiz_data}")
#             return quiz_data
#         else:
#             logging.warning(f"Could not find a valid JSON array in cleaned text. Cleaned output: {clean_generated_text[:500]}...")
#             return {"error": f"Could not parse quiz. The model did not return a recognizable JSON array. Cleaned output (first 500 chars): {clean_generated_text[:500]}... Raw output (first 500 chars): {raw_generated_text[:500]}... Please try again or rephrase the topic."}
#     except json.JSONDecodeError as e:
#         logging.error(f"JSON decoding error: {e} from text: {clean_generated_text} (attempted JSON string: {json_str})", exc_info=True)
#         return {"error": f"Failed to parse quiz: Invalid JSON format. Error: {e}. Attempted JSON (first 500 chars): {json_str[:500]}... Cleaned output (first 500 chars): {clean_generated_text[:500]}... Raw output (first 500 chars): {raw_generated_text[:500]}... Please try again."}
#     except Exception as e:
#         logging.error(f"Error generating quiz: {e}", exc_info=True)
#         return {"error": f"An unexpected error occurred during quiz generation: {e}"}
# 
# 
# def assess_response(question: str, options: list, correct_answer_key: str, student_answer_key: str):
#     """Assesses a student's response and provides feedback."""
#     is_correct = student_answer_key == correct_answer_key
#     feedback_prompt = (
#         f"Question: \"{question}\"\n"
#         f"Options: {', '.join(options)}\n"
#         f"Correct Answer: {correct_answer_key}\n"
#         f"Student's Answer: {student_answer_key}\n\n"
#         f"Based on the above, provide concise feedback to the student. "
#     )
#     if is_correct:
#         feedback_prompt += "Congratulate them and briefly explain why their answer is correct."
#     else:
#         feedback_prompt += "Gently correct them, explain why their answer is incorrect, and briefly explain the correct concept."
# 
#     if text_generator is None:
#         return "AI model not loaded for feedback."
# 
#     try:
#         result = text_generator(feedback_prompt)
#         feedback_text = result[0]['generated_text'].replace(feedback_prompt, "", 1).strip() # Replace only first occurrence
#         # Clean up common LLM conversational prefixes/suffixes
#         if feedback_text.lower().startswith("assistant:"):
#             feedback_text = feedback_text[len("assistant:"):].strip()
#         if feedback_text.lower().startswith("human:"): # Sometimes model might generate next turn
#             feedback_text = ""
#         if not feedback_text:
#             feedback_text = "Feedback could not be generated clearly. Please try again."
# 
#         return feedback_text
#     except Exception as e:
#         logging.error(f"Error assessing response: {e}", exc_info=True)
#         return f"Error providing feedback: {e}"
# 
# def analyze_diagnostic_results(results: dict):
#     """Analyzes diagnostic test results and suggests adaptive learning paths."""
#     # If you want to use Watsonx for this, uncomment the watsonx_llm check and usage
#     # if watsonx_llm is None:
#     #     return "IBM Watsonx model not loaded for diagnostic analysis."
#     if text_generator is None: # Using the primary HF model for now
#         return "AI model not loaded for diagnostic analysis."
# 
#     summary_text = "Diagnostic Test Results:\n"
#     for topic, score in results.items():
#         summary_text += f"- {topic}: {score}/100\n"
# 
#     prompt = (
#         f"Based on the following diagnostic test results, provide a personalized learning recommendation. "
#         f"Suggest topics for improvement and areas of strength. Also, suggest how quiz difficulty should be adapted (e.g., 'start with easy quizzes on X, medium on Y').\n\n"
#         f"{summary_text}\n\nRecommendation:"
#     )
#     try:
#         # If using Watsonx: recommendation_text = watsonx_llm.invoke(prompt)
#         result = text_generator(prompt) # Using the primary HF model for now
#         recommendation_text = result[0]['generated_text'].replace(prompt, "", 1).strip() # Replace only first occurrence
#         if recommendation_text.lower().startswith("assistant:"):
#             recommendation_text = recommendation_text[len("assistant:"):].strip()
#         return recommendation_text
#     except Exception as e:
#         logging.error(f"Error analyzing diagnostic results: {e}", exc_info=True)
#         return f"Error analyzing diagnostic results: {e}"
# 
# 
# # --- 3. Google Classroom Integration (Mock/Placeholder) ---
# # You will need to set up a Google Cloud Project, enable the Classroom API,
# # and download your client_secret.json. Place it in the same directory as this script.
# # SCOPES = ['[https://www.googleapis.com/auth/classroom.courses.readonly](https://www.googleapis.com/auth/classroom.courses.readonly)',
# #           '[https://www.googleapis.com/auth/classroom.profile.emails](https://www.googleapis.com/auth/classroom.profile.emails)',
# #           '[https://www.googleapis.com/auth/classroom.profile.photos](https://www.googleapis.com/auth/classroom.profile.photos)',
# #           '[https://www.googleapis.com/auth/classroom.rosters.readonly](https://www.googleapis.com/auth/classroom.rosters.readonly)']
# 
# # def get_google_auth_flow():
# #     """Initializes Google OAuth 2.0 flow."""
# #     # The client_secrets.json file needs to be in the same directory as your app.
# #     # Download it from Google Cloud Console -> APIs & Services -> Credentials
# #     # Create OAuth 2.0 Client ID (Web application type)
# #     if not os.path.exists('client_secret.json'):
# #         st.error("`client_secret.json` not found! Please download it from Google Cloud Console.")
# #         st.stop() # Stop execution if credentials are missing
# #     return Flow.from_client_secrets_file(
# #         'client_secret.json', SCOPES, redirect_uri='http://localhost:8501' # Adjust redirect_uri for Ngrok
# #     )
# 
# # def authenticate_google_classroom():
# #     """Handles Google Classroom authentication."""
# #     creds = None
# #     # The file token.pickle stores the user's access and refresh tokens, and is
# #     # created automatically when the authorization flow completes for the first time.
# #     if os.path.exists('token.pickle'):
# #         with open('token.pickle', 'rb') as token:
# #             creds = pickle.load(token)
# #     # If there are no (valid) credentials available, let the user log in.
# #     if not creds or not creds.valid:
# #         if creds and creds.expired and creds.refresh_token:
# #             creds.refresh(Request())
# #         else:
# #             flow = get_google_auth_flow()
# #             auth_url, _ = flow.authorization_url(prompt='consent')
# #             st.write(f"Please go to this URL to authorize: {auth_url}")
# #             # User needs to manually paste the redirect URL after authorization
# #             auth_code = st.text_input("Enter the authorization code from the redirect URL:")
# #             if auth_code:
# #                 flow.fetch_token(code=auth_code)
# #                 creds = flow.credentials
# #                 # Save the credentials for the next run
# #                 with open('token.pickle', 'wb') as token:
# #                     pickle.dump(creds, token)
# #     return creds
# 
# # @st.cache_data
# # def get_classroom_courses(creds):
# #     """Fetches courses from Google Classroom."""
# #     try:
# #         service = build('classroom', 'v1', credentials=creds)
# #         results = service.courses().list(pageSize=10).execute()
# #         courses = results.get('courses', [])
# #         return courses
# #     except Exception as e:
# #         st.error(f"Error fetching Google Classroom courses: {e}")
# #         return []
# 
# # Mock Google Classroom data for demonstration without full OAuth setup
# def mock_get_classroom_courses():
#     """Mocks fetching courses from Google Classroom."""
#     st.info("Using mock Google Classroom data. For real integration, set up `client_secret.json`.")
#     return [
#         {"id": "course1", "name": "Introduction to Python", "section": "Fall 2024", "descriptionHeading": "Programming Basics"},
#         {"id": "course2", "name": "Calculus I", "section": "Fall 2024", "descriptionHeading": "Mathematics"},
#         {"id": "course3", "name": "World History", "section": "Spring 2025", "descriptionHeading": "Humanities"},
#     ]
# 
# 
# # --- 4. Pinecone Vector DB Integration ---
# @st.cache_resource
# def init_pinecone(api_key, index_name, environment): # Added arguments
#     """Initializes Pinecone client."""
#     if not api_key or not index_name or not environment: # Use arguments
#         st.warning("Pinecone API Key, Index Name, or Environment not set. Pinecone integration will be mocked.")
#         return None
#     try:
#         # Initialize Pinecone with API key and environment
#         pc = Pinecone(api_key=api_key, environment=environment) # Use arguments
# 
#         # Check if the index exists, if not, create it
#         if index_name not in pc.list_indexes(): # Use arguments
#             logging.info(f"Pinecone index '{index_name}' not found. Attempting to create it...") # Use arguments
#             try:
#                 pc.create_index(
#                     name=index_name, # Use arguments
#                     dimension=1024, # Assuming 1024 for llama-text-embed-v2, adjust if using a different model
#                     metric='cosine', # Common metric for text embeddings
#                     spec=ServerlessSpec(cloud='aws', region=environment) # Use arguments
#                 )
#                 st.success(f"Pinecone index '{index_name}' created successfully!") # Use arguments
#                 logging.info(f"Pinecone index '{index_name}' created.") # Use arguments
#             except Exception as create_e:
#                 # Catch specific error if index already exists from a race condition or previous run
#                 if "already exists" in str(create_e):
#                     # Removed st.info message for existing index from UI
#                     logging.info(f"Pinecone index '{index_name}' already exists. Skipping creation.") # Use arguments
#                 else:
#                     raise create_e # Re-raise if it's another type of creation error
# 
#         # Access the index
#         index = pc.Index(index_name) # Use arguments
#         logging.info(f"Connected to Pinecone index: {index_name}") # Use arguments
#         return index
#     except Exception as e:
#         logging.error(f"Error initializing Pinecone: {e}", exc_info=True)
#         st.error(f"Failed to connect or create Pinecone index: {e}. Check your API key, index name, and environment.")
#         return None
# 
# # Pass the global variables to the init_pinecone function
# pinecone_index = init_pinecone(PINECONE_API_KEY, PINECONE_INDEX_NAME, PINECONE_ENVIRONMENT)
# 
# # In-memory mock for student data and quiz history (used if Pinecone is not active)
# # This will reset every time the Streamlit app reruns or Colab restarts.
# # For persistence, Pinecone or another database is required.
# if 'student_db' not in st.session_state:
#     st.session_state.student_db = {} # student_id: {name, courses: [], quiz_history: []}
# if 'educator_db' not in st.session_state:
#     st.session_state.educator_db = {"admin": "password"} # Simple mock for educator login
# 
# def get_student_profile(student_id):
#     # In a real Pinecone integration, you'd fetch the student profile vector here
#     # For now, use in-memory mock
#     return st.session_state.student_db.get(student_id, {"quiz_history": []})
# 
# def update_student_quiz_history(student_id, quiz_data):
#     # In a real Pinecone integration, you'd update the student's vector/metadata here
#     # For now, use in-memory mock
#     if student_id not in st.session_state.student_db:
#         st.session_state.student_db[student_id] = {"quiz_history": []}
#     st.session_state.student_db[student_id]["quiz_history"].append(quiz_data)
# 
# def get_all_student_quiz_history():
#     # In a real Pinecone integration, you'd query all relevant student data
#     # For now, use in-memory mock
#     all_history = []
#     for student_id, data in st.session_state.student_db.items():
#         for quiz in data.get("quiz_history", []):
#             all_history.append({"student_id": student_id, **quiz})
#     return all_history
# 
# 
# # --- 5. Streamlit Frontend UI ---
# 
# st.set_page_config(page_title="EduTutor AI", layout="wide", initial_sidebar_state="expanded")
# 
# # Custom CSS for styling
# st.markdown("""
#     <style>
#     .main-header {
#         font-size: 3em;
#         font-weight: bold;
#         color: #1E40AF; /* blue-800 */
#         text-align: center;
#         margin-bottom: 30px;
#     }
#     .stButton>button {
#         background-color: #3B82F6; /* blue-500 */
#         color: white;
#         border-radius: 0.5rem;
#         padding: 0.75rem 1.5rem;
#         font-size: 1rem;
#         font-weight: bold;
#         transition: all 0.3s ease;
#         box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
#     }
#     .stButton>button:hover {
#         background-color: #2563EB; /* blue-600 */
#         transform: translateY(-2px);
#         box-shadow: 0 6px 8px rgba(0, 0, 0, 0.15);
#     }
#     .stTextInput>div>div>input {
#         border-radius: 0.5rem;
#         border: 1px solid #D1D5DB; /* gray-300 */
#         padding: 0.75rem;
#     }
#     .stSelectbox>div>div {
#         border-radius: 0.5rem;
#         border: 1px solid #D1D5DB; /* gray-300 */
#         padding: 0.5rem;
#     }
#     /* More aggressive CSS to ensure text visibility in the selectbox */
#     .stSelectbox [data-baseweb="select"] > div:first-child > div:first-child,
#     .stSelectbox [data-baseweb="select"] span,
#     .stSelectbox [data-baseweb="select"] div[role="button"] > div,
#     .stSelectbox [data-baseweb="select"] input[type="text"],
#     .stSelectbox [data-baseweb="select"] .st-cq,
#     .stSelectbox [data-baseweb="select"] .st-b {
#         color: black !important; /* Force text to be black */
#         -webkit-text-fill-color: black !important; /* For Safari/WebKit browsers */
#         opacity: 1 !important; /* Ensure full opacity */
#     }
#     /* Also ensure the background of the selectbox itself is not an issue */
#     .stSelectbox [data-baseweb="select"] > div:first-child {
#         background-color: white !important; /* Ensure a white background for contrast */
#     }
# 
#     .quiz-question {
#         background-color: #F3F4F6; /* gray-100 */
#         padding: 15px;
#         border-radius: 0.5rem;
#         margin-bottom: 15px;
#         border-left: 5px solid #3B82F6;
#     }
#     .quiz-option {
#         margin-bottom: 5px;
#     }
#     .feedback-correct {
#         color: #10B981; /* green-600 */
#         font-weight: bold;
#     }
#     .feedback-incorrect {
#         color: #EF4444; /* red-600 */
#         font-weight: bold;
#     }
#     .stAlert {
#         border-radius: 0.5rem;
#     }
#     .sidebar .st-emotion-cache-1ddn9h6 { /* Adjust sidebar width */
#         width: 250px;
#     }
#     </style>
# """, unsafe_allow_html=True)
# 
# # --- Session State Management for Navigation and Login ---
# if 'page' not in st.session_state:
#     st.session_state.page = 'home'
# if 'logged_in_student' not in st.session_state:
#     st.session_state.logged_in_student = None
# if 'logged_in_educator' not in st.session_state:
#     st.session_state.logged_in_educator = None
# if 'current_quiz' not in st.session_state:
#     st.session_state.current_quiz = None
# if 'quiz_results' not in st.session_state:
#     st.session_state.quiz_results = None
# if 'diagnostic_results' not in st.session_state:
#     st.session_state.diagnostic_results = None
# 
# 
# # --- Navigation Sidebar ---
# with st.sidebar:
#     st.title("EduTutor AI ü§ñ")
#     st.markdown("---")
# 
#     if st.button("üè† Home"):
#         st.session_state.page = 'home'
#     if st.button("üéì Student Panel"):
#         st.session_state.page = 'student_login'
#     if st.button("üßë‚Äçüè´ Educator Panel"):
#         st.session_state.page = 'educator_login'
# 
#     st.markdown("---")
#     if st.session_state.logged_in_student:
#         st.write(f"Logged in as Student: {st.session_state.logged_in_student}")
#         if st.button("Logout Student"):
#             st.session_state.logged_in_student = None
#             st.session_state.page = 'home'
#             st.rerun()
#     elif st.session_state.logged_in_educator:
#         st.write(f"Logged in as Educator: {st.session_state.logged_in_educator}")
#         if st.button("Logout Educator"):
#             st.session_state.logged_in_educator = None
#             st.session_state.page = 'home'
#             st.rerun()
# 
# # --- Main Page Content ---
# 
# def home_page():
#     st.markdown("<h1 class='main-header'>Welcome to EduTutor AI!</h1>", unsafe_allow_html=True)
#     st.markdown("""
#     <p style='font-size: 1.2em; text-align: center; margin-bottom: 20px;'>
#         Your personalized learning companion powered by Generative AI and seamlessly integrated with your learning environment.
#     </p>
#     """, unsafe_allow_html=True)
# 
#     # Replaced st.image with inline HTML/CSS for the banner
#     st.markdown("""
#         <div style="background-color: #ADD8E6; border-radius: 0.5rem; padding: 40px; text-align: center; margin-bottom: 30px;">
#             <h2 style="color: #000000; font-size: 2.5em; font-weight: bold;">EduTutor AI Banner</h2>
#             <p style="color: #000000; font-size: 1.1em;">Personalized Learning Journey</p>
#         </div>
#     """, unsafe_allow_html=True)
# 
#     st.subheader("Key Features:")
#     col1, col2 = st.columns(2)
#     with col1:
#         st.info("‚ú® **Personalized Learning Experience:** Adaptive quizzes and instant feedback tailored to your needs.")
#         st.info("üìä **Educator Dashboard:** Real-time insights into student performance.")
#     with col2:
#         st.info("üß† **Diagnostic Testing:** AI-driven assessment to pinpoint strengths and weaknesses.")
#         st.info("üîó **Google Classroom Integration:** Seamless synchronization of courses and data.")
# 
#     st.markdown("---")
#     st.write("Choose a panel from the sidebar to get started!")
# 
# def student_login_page():
#     st.markdown("<h2 class='main-header'>Student Login</h2>", unsafe_allow_html=True)
#     st.write("Login or sync with Google Classroom to access your personalized learning experience.")
# 
#     # Simple mock login for student (can be replaced by full Google OAuth)
#     with st.form("student_mock_login"):
#         st.write("### Mock Student Login")
#         student_id_input = st.text_input("Enter Student ID (e.g., 'student1')", key="mock_student_id")
#         submitted = st.form_submit_button("Login as Student")
#         if submitted:
#             if student_id_input:
#                 st.session_state.logged_in_student = student_id_input
#                 st.session_state.page = 'student_dashboard'
#                 st.success(f"Logged in as {student_id_input}")
#                 st.rerun()
#             else:
#                 st.error("Please enter a Student ID.")
# 
#     st.markdown("---")
#     st.write("### Google Classroom Synchronization")
#     st.info("This section demonstrates Google Classroom integration. For a live demo, you need to set up Google Cloud Project credentials and enable the Classroom API.")
# 
#     if st.button("Sync with Google Classroom"):
#         # For a full implementation, uncomment and use the actual Google OAuth flow
#         # creds = authenticate_google_classroom()
#         # if creds:
#         #     st.session_state.google_creds = creds
#         #     st.session_state.logged_in_student = "Google_Classroom_User" # Assign a generic ID
#         #     st.session_state.page = 'student_dashboard'
#         #     st.success("Successfully synced with Google Classroom!")
#         #     st.rerun()
#         # else:
#         #     st.warning("Please complete Google Classroom authentication.")
# 
#         # Using mock data for demonstration
#         st.session_state.logged_in_student = "Mock_Google_Student"
#         st.session_state.page = 'student_dashboard'
#         st.success("Successfully synced with Google Classroom (using mock data)!)")
#         st.rerun()
# 
# 
# def student_dashboard_page():
#     if not st.session_state.logged_in_student:
#         st.warning("Please login to access the student dashboard.")
#         student_login_page()
#         return
# 
#     st.markdown(f"<h2 class='main-header'>Student Dashboard - {st.session_state.logged_in_student}</h2>", unsafe_allow_html=True)
# 
#     st.subheader("Your Courses (Google Classroom Integration)")
#     # courses = get_classroom_courses(st.session_state.google_creds) # For real integration
#     courses = mock_get_classroom_courses() # Using mock data
# 
#     if courses:
#         st.write("Here are your synchronized courses from Google Classroom:")
#         for course in courses:
#             st.write(f"- **{course['name']}** ({course.get('section', 'N/A')}) - Topic: {course.get('descriptionHeading', 'General')}")
#         st.session_state.available_topics = [c.get('descriptionHeading', 'General') for c in courses if c.get('descriptionHeading')]
#         st.session_state.available_topics = list(set(st.session_state.available_topics)) # Unique topics
#         if "General" not in st.session_state.available_topics:
#              st.session_state.available_topics.append("General")
#     else:
#         st.warning("No courses found or synced from Google Classroom. Please sync your courses.")
#         st.session_state.available_topics = ["General", "Science", "Math", "History"] # Default topics
# 
#     st.markdown("---")
#     st.subheader("Personalized Learning Journey")
#     if st.button("Take a New Quiz"):
#         st.session_state.page = 'take_quiz'
#         st.session_state.current_quiz = None # Reset current quiz
#         st.session_state.quiz_results = None # Reset results
#         st.rerun()
# 
#     if st.button("View Quiz History"):
#         st.session_state.page = 'quiz_history'
#         st.rerun()
# 
#     if st.button("Take Diagnostic Test"):
#         st.session_state.page = 'diagnostic_test'
#         st.session_state.diagnostic_results = None
#         st.rerun()
# 
# 
# def take_quiz_page():
#     if not st.session_state.logged_in_student:
#         st.warning("Please login to take a quiz.")
#         student_login_page()
#         return
# 
#     st.markdown(f"<h2 class='main-header'>Take a Quiz - {st.session_state.logged_in_student}</h2>", unsafe_allow_html=True)
# 
#     if st.session_state.current_quiz is None:
#         st.subheader("Generate New Quiz")
# 
#         # Ensure available_topics is populated before trying to use it
#         if 'available_topics' not in st.session_state or not st.session_state.available_topics:
#             st.session_state.available_topics = ["General", "Science", "Math", "History"] # Fallback if not set by Classroom mock
# 
#         # Initialize selected_quiz_topic if it's not already set
#         if 'selected_quiz_topic' not in st.session_state or st.session_state.selected_quiz_topic not in st.session_state.available_topics:
#             st.session_state.selected_quiz_topic = st.session_state.available_topics[0] # Default to the first available topic
# 
#         # Determine the default index for the selectbox
#         default_topic_index = st.session_state.available_topics.index(st.session_state.selected_quiz_topic)
# 
#         quiz_topic = st.selectbox(
#             "Select a topic for your quiz:",
#             st.session_state.available_topics,
#             index=default_topic_index, # Set the index to display the last selected topic
#             key="quiz_topic_selector"
#         )
#         num_questions = st.slider("Number of questions:", min_value=1, max_value=5, value=3)
# 
#         if st.button("Generate Quiz"):
#             st.session_state.selected_quiz_topic = quiz_topic # Store selected topic for persistence
#             with st.spinner(f"Generating a {num_questions}-question quiz on '{quiz_topic}'..."):
#                 quiz = generate_quiz(quiz_topic, num_questions)
#                 if "error" in quiz:
#                     st.error(quiz["error"])
#                     st.session_state.current_quiz = None
#                 else:
#                     st.session_state.current_quiz = {"topic": quiz_topic, "questions": quiz}
#                     st.session_state.quiz_results = {"answers": {}, "score": 0, "feedback": []}
#                     st.success("Quiz generated successfully!")
#                     st.rerun() # Rerun to display the quiz questions
#     else:
#         st.subheader(f"Quiz on: {st.session_state.current_quiz['topic']}") # Display stored topic
#         quiz_questions = st.session_state.current_quiz["questions"]
#         student_answers = st.session_state.quiz_results["answers"]
# 
#         with st.form("quiz_form"):
#             for i, q_data in enumerate(quiz_questions):
#                 st.markdown(f"**Question {i+1}:** {q_data['question']}")
#                 selected_option = st.radio(
#                     "Select your answer:",
#                     options=q_data['options'], # Display full options, e.g., "A. Option Text"
#                     key=f"q_{i}",
#                     index=None # No option selected by default
#                 )
#                 if selected_option:
#                     # Extract just the letter (A, B, C, D) from the selected option for storage
#                     student_answers[f"q_{i}"] = selected_option.split('. ')[0]
# 
#             submitted = st.form_submit_button("Submit Quiz")
#             if submitted:
#                 score = 0
#                 feedback_list = []
#                 for i, q_data in enumerate(quiz_questions):
#                     question_key = f"q_{i}"
#                     student_ans = student_answers.get(question_key)
#                     correct_ans = q_data['correct_answer']
# 
#                     if student_ans == correct_ans:
#                         score += 1
#                         feedback_list.append(f"Q{i+1}: Correct!")
#                     else:
#                         feedback_list.append(f"Q{i+1}: Incorrect. Correct answer was {correct_ans}.")
# 
#                     # Generate detailed feedback using LLM
#                     with st.spinner(f"Generating feedback for Q{i+1}..."):
#                         detailed_feedback = assess_response(
#                             q_data['question'],
#                             q_data['options'],
#                             q_data['correct_answer'],
#                             student_ans if student_ans else "No Answer"
#                         )
#                         feedback_list[-1] += f" Detailed Feedback: {detailed_feedback}"
# 
# 
#                 st.session_state.quiz_results["score"] = score
#                 st.session_state.quiz_results["feedback"] = feedback_list
#                 st.session_state.quiz_results["timestamp"] = datetime.now().isoformat()
#                 st.session_state.quiz_results["total_questions"] = len(quiz_questions)
# 
#                 # Update in-memory student database (mock Pinecone)
#                 update_student_quiz_history(
#                     st.session_state.logged_in_student,
#                     {
#                         "topic": st.session_state.current_quiz["topic"],
#                         "score": score,
#                         "total_questions": len(quiz_questions),
#                         "timestamp": st.session_state.quiz_results["timestamp"]
#                     }
#                 )
#                 st.success("Quiz submitted! See results below.")
#                 st.rerun() # Rerun to display results
# 
#         if st.session_state.quiz_results and st.session_state.quiz_results["feedback"]:
#             st.markdown("---")
#             st.subheader("Quiz Results & Feedback")
#             st.write(f"You scored: {st.session_state.quiz_results['score']} out of {st.session_state.quiz_results['total_questions']}")
#             for fb in st.session_state.quiz_results["feedback"]:
#                 if "Correct!" in fb:
#                     st.markdown(f"<span class='feedback-correct'>{fb}</span>", unsafe_allow_html=True)
#                 else:
#                     st.markdown(f"<span class='feedback-incorrect'>{fb}</span>", unsafe_allow_html=True)
# 
#             if st.button("Take Another Quiz"):
#                 st.session_state.current_quiz = None
#                 st.session_state.quiz_results = None
#                 st.rerun()
#             if st.button("Back to Dashboard"):
#                 st.session_state.page = 'student_dashboard'
#                 st.rerun()
# 
# def quiz_history_page():
#     if not st.session_state.logged_in_student:
#         st.warning("Please login to view quiz history.")
#         student_login_page()
#         return
# 
#     st.markdown(f"<h2 class='main-header'>Quiz History - {st.session_state.logged_in_student}</h2>", unsafe_allow_html=True)
# 
#     student_profile = get_student_profile(st.session_state.logged_in_student)
#     quiz_history = student_profile.get("quiz_history", [])
# 
#     if quiz_history:
#         st.write("Here's a summary of your past quizzes:")
#         for i, quiz in enumerate(quiz_history):
#             st.markdown(f"**Quiz {i+1}:**")
#             st.write(f"  - Topic: {quiz['topic']}")
#             st.write(f"  - Score: {quiz['score']}/{quiz['total_questions']}")
#             st.write(f"  - Date: {datetime.fromisoformat(quiz['timestamp']).strftime('%Y-%m-%d %H:%M')}")
#             st.markdown("---")
#     else:
#         st.info("You haven't taken any quizzes yet. Go to the dashboard to start one!")
# 
#     if st.button("Back to Dashboard"):
#         st.session_state.page = 'student_dashboard'
#     st.rerun()
# 
# def diagnostic_test_page():
#     if not st.session_state.logged_in_student:
#         st.warning("Please login to take a diagnostic test.")
#         student_login_page()
#         return
# 
#     st.markdown(f"<h2 class='main-header'>Diagnostic Test - {st.session_state.logged_in_student}</h2>", unsafe_allow_html=True)
#     st.write("This test helps EduTutor AI understand your strengths and weaknesses to adapt future quizzes.")
# 
#     if st.session_state.diagnostic_results is None:
#         st.subheader("Answer these questions to assess your knowledge:")
#         # Mock diagnostic questions for various topics
#         diagnostic_questions = {
#             "Algebra": "What is the value of x in 2x + 5 = 15?",
#             "Biology": "What is the powerhouse of the cell?",
#             "History": "Who was the first President of the United States?",
#             "Physics": "What is Newton's second law of motion?",
#         }
# 
#         user_answers = {}
#         for topic, question in diagnostic_questions.items():
#             user_answers[topic] = st.text_input(f"**{topic}:** {question}", key=f"diag_{topic}")
# 
#         if st.button("Submit Diagnostic Test"):
#             # Simulate scoring (e.g., based on length of answer, or just random for demo)
#             simulated_scores = {}
#             for topic, answer in user_answers.items():
#                 # A real diagnostic test would involve LLM grading or pre-defined answers
#                 # For demo, let's give a random score based on answer presence
#                 simulated_scores[topic] = 70 + (len(answer) % 30) if answer else 30 # Score between 30-99
# 
#             st.session_state.diagnostic_results = simulated_scores
#             st.success("Diagnostic test submitted! Analyzing results...")
#             st.rerun()
#     else:
#         st.subheader("Diagnostic Test Results & Personalized Recommendation")
#         st.write("Here are your scores for each topic:")
#         for topic, score in st.session_state.diagnostic_results.items():
#             st.write(f"- **{topic}:** {score}/100")
# 
#         with st.spinner("Generating personalized learning recommendation..."):
#             recommendation = analyze_diagnostic_results(st.session_state.diagnostic_results)
#             st.markdown("---")
#             st.subheader("Personalized Learning Recommendation:")
#             st.write(recommendation)
#             st.info("Based on these results, EduTutor AI will adapt the difficulty and topics of your future quizzes (e.g., more easy quizzes on areas of improvement, challenging quizzes on strengths).")
# 
#         if st.button("Back to Dashboard"):
#             st.session_state.page = 'student_dashboard'
#             st.rerun()
# 
# 
# def educator_login_page():
#     st.markdown("<h2 class='main-header'>Educator Login</h2>", unsafe_allow_html=True)
#     st.write("Login to view student performance insights.")
# 
#     with st.form("educator_login_form"):
#         st.markdown("**Default Educator Login:** Username `admin`, Password `password`")
#         username = st.text_input("Username", key="educator_username").strip()
#         password = st.text_input("Password", type="password", key="educator_password").strip()
#         submitted = st.form_submit_button("Login")
# 
#         if submitted:
#             # Removed logging from UI, it will still appear in Colab console for debugging
#             logging.info(f"Attempting educator login. Username entered: '{username}', Password entered: '{password}'")
#             logging.info(f"Stored educator_db: {st.session_state.educator_db}")
#             if username in st.session_state.educator_db and st.session_state.educator_db[username] == password:
#                 st.session_state.logged_in_educator = username
#                 st.session_state.page = 'educator_dashboard'
#                 st.success(f"Welcome, {username}!")
#                 st.rerun()
#             else:
#                 st.error("Invalid username or password.")
# 
# def educator_dashboard_page():
#     if not st.session_state.logged_in_educator:
#         st.warning("Please login to access the educator dashboard.")
#         educator_login_page()
#         return
# 
#     st.markdown(f"<h2 class='main-header'>Educator Dashboard - {st.session_state.logged_in_educator}</h2>", unsafe_allow_html=True)
#     st.write("Real-time quiz performance insights for all students.")
# 
#     all_quiz_history = get_all_student_quiz_history()
# 
#     if not all_quiz_history:
#         st.info("No student quiz data available yet. Students need to take quizzes first.")
#         return
# 
#     st.subheader("Overall Student Performance Summary")
# 
#     # Aggregate data for display
#     student_performance = {}
#     for quiz in all_quiz_history:
#         student_id = quiz['student_id']
#         if student_id not in student_performance:
#             student_performance[student_id] = {
#                 "total_quizzes": 0,
#                 "total_score": 0,
#                 "total_questions": 0,
#                 "last_topic": "N/A",
#                 "last_score": "N/A",
#                 "last_attempt_date": "N/A"
#             }
# 
#         student_performance[student_id]["total_quizzes"] += 1
#         student_performance[student_id]["total_score"] += quiz['score']
#         student_performance[student_id]["total_questions"] += quiz['total_questions']
#         student_performance[student_id]["last_topic"] = quiz['topic']
#         student_performance[student_id]["last_score"] = f"{quiz['score']}/{quiz['total_questions']}"
#         student_performance[student_id]["last_attempt_date"] = datetime.fromisoformat(quiz['timestamp']).strftime('%Y-%m-%d %H:%M')
# 
#     # Display in a table
#     st.write("### Student Quiz History Overview")
#     data_for_table = []
#     for student_id, data in student_performance.items():
#         avg_score = (data["total_score"] / data["total_questions"] * 100) if data["total_questions"] > 0 else 0
#         data_for_table.append({
#             "Student ID": student_id,
#             "Total Quizzes": data["total_quizzes"],
#             "Average Score (%)": f"{avg_score:.2f}",
#             "Last Topic Attempted": data["last_topic"],
#             "Last Score": data["last_score"],
#             "Last Attempt Date": data["last_attempt_date"]
#         })
# 
#     st.dataframe(data_for_table, use_container_width=True)
# 
#     # You could add charts here using st.bar_chart or st.line_chart
#     # For example, a bar chart of average scores per student
#     # student_ids = [d["Student ID"] for d in data_for_table]
#     # avg_scores = [float(d["Average Score (%)"]) for d in data_for_table]
#     # st.bar_chart(pd.DataFrame({'Student': student_ids, 'Average Score': avg_scores}).set_index('Student'))
# 
# # --- Page Routing ---
# if st.session_state.page == 'home':
#     home_page()
# elif st.session_state.page == 'student_login':
#     student_login_page()
# elif st.session_state.page == 'student_dashboard':
#     student_dashboard_page()
# elif st.session_state.page == 'take_quiz':
#     take_quiz_page()
# elif st.session_state.page == 'quiz_history':
#     quiz_history_page()
# elif st.session_state.page == 'diagnostic_test':
#     diagnostic_test_page()
# elif st.session_state.page == 'educator_login':
#     educator_login_page()
# elif st.session_state.page == 'educator_dashboard':
#     educator_dashboard_page()
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile run_streamlit_and_ngrok.py
# from pyngrok import ngrok, conf
# import subprocess
# import threading
# import time
# import os
# 
# # Set Ngrok authtoken
# # Your provided Ngrok token is inserted directly here.
# conf.get_default().auth_token = os.environ.get("NGROK_AUTH_TOKEN", "2z2tuNwzSHqpRx3xbCbWHjG1dRc_4ix8ZspVPU4cgQ7wrfDew")
# 
# # Kill any running ngrok processes
# print("Killing any existing Ngrok tunnels...")
# ngrok.kill()
# time.sleep(2)
# 
# # Function to run Streamlit
# def run_streamlit():
#     # This assumes edututor_app.py is in the same directory
#     streamlit_cmd = ["streamlit", "run", "edututor_app.py", "--server.port", "8501", "--server.headless", "true"]
#     subprocess.run(streamlit_cmd)
# 
# # Start Streamlit in a separate thread
# streamlit_thread = threading.Thread(target=run_streamlit)
# streamlit_thread.daemon = True
# streamlit_thread.start()
# 
# print("Streamlit app started in background on port 8501.")
# time.sleep(5) # Give Streamlit a moment to start
# 
# # Establish Ngrok tunnel
# try:
#     public_url = ngrok.connect(8501).public_url
#     print(f"Your EduTutor AI app is live! Access it at: {public_url}")
#     # In a real Streamlit app, you'd use st.write, but here we're in a separate script
#     # so we'll just print to console.
#     print(f"EduTutor AI is running! Click the link below to access:")
#     print(f"### EduTutor AI Live App: {public_url}")
# except Exception as e:
#     print(f"Error establishing Ngrok tunnel: {e}")
#     print(f"Failed to establish Ngrok tunnel: {e}. Please check your Ngrok Auth Token.")
# 
# # Keep the Colab cell alive while Streamlit runs
# # This loop will continue until the cell is manually stopped
# while True:
#     time.sleep(60)
#

# Cell 4: Run the Ngrok Runner Script
!python run_streamlit_and_ngrok.py